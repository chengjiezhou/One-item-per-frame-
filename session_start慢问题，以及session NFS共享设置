nfs 共享session方式 session_start 慢 有关问题解决
www.MyException.Cn  网友分享于：2015-08-26  浏览：288次
nfs 共享session方式 session_start 慢 问题解决

       近几天php搭建了个新的运行平台，但出了个问题，就是显示登录状态的页面打开卡的时间有点长。这个很明显是读取会话状态的操作时产生，但就是搞不明白是怎么回事。

       因为php方面有所改动，在访问会话时产生，很自然想到会不会是PHP的问题，或者NFS的负载高了？

       首先是重装一次PHP，换用原来一模一样的环境，问题依旧，再使用PHP性能检测工具，问题确实是出现在session_start()的时候。 是不是性能问题呢？ 于是乎又是一番对NFS的检查，优化。。。均告无效。

　　上网搜索，此类问题均被作为PHP　BUG来提问 =。= 

      很偶然的情况下，我想，会不会是nfslock服务停掉了的原因呢？  启动服务后一切正常。哈哈。

      这才想起，做初始化脚本时，认为一般系统是不运行NFS的，当有需要时再开，因此关掉了很多认为少用到的服务。

 

 

关键字：Very Slow session_start on nfs-mount   Session_start Is Slow

 

 

另外有一种情况，运行PHP时，使用NFS方式测试性能下降明显，原因是open_basedir 的设置问题。单机环境去掉即可。或：     ../:./:/tmp:../../

 

 

 

至于设置多个domain,写多几行就行。

session.cookie_domain =abc.com
session.cookie_domain =abcd.com

 

 

 

 

 

 

 

 

 

 

 

 

服务器是使用session NFS共享方式实现了的！session NFS共享方式配置如下：

http://www.linuxdiyf.com/viewarticle.php?id=161086

 

首先，修改 php.ini的 session.save_path 选项修改如下：

session.save_path = "2;/tmp/php_sess" （去掉前面分号）

意为把session存放在 "/tmp/php_sess" 目录下，并且分成 2 级子目录，每级子目录又分别有 16 个子目录。


2.假设php的主目录为 /usr/local/server/php/，则新建一个文件 /usr/local/server/php/include/php/ext/session/mod_files.sh，其内容如下：
#! /bin/sh
# NAME
# mod_files.sh - Update of the php-source/ext/session/mod_files.sh
#
# SYNOPSIS
# mod_files.sh basedir depth [numberofsubdirs]
#
# DESCRIPTION
# this script creates the directories tree used by php to store the session files
# (see php.ini - 'session.save_path' option)
#
# Example: if you want php to store the session files in a directory tree
# of 3 levels of depth containing 32 directories in each directory,
# first, put the setting bellow in the php.ini file:
#
# session.save_path = "3;/tmp/session"
#
# Now create the basedir directory: 'mkdir /tmp/session'
#
# Then, call this scrip with the following arguments:
#
# ./mod_files.sh ./mod_files.sh /tmp/session 3 32

if test "$2" = ""; then
echo "usage: $0 basedir depth [numberofsubdirs]"
echo "numberofsubdirs: if unset, defaults to 16. if 32, 32 subdirs, if 64, 64 subdirs."
exit 1
fi

if test "$2" = "0"; then
exit 0
fi

hash_chars="0 1 2 3 4 5 6 7 8 9 a b c d e f"
if [ ! -z $3 ] ; then
if test "$3" -a "$3" -eq "32"; then
hash_chars="$hash_chars g h i j k l m n o p q r s t u v"
if test "$3" -eq "64"; then
hash_chars="$hash_chars w x y z A B C D E F G H I J K L M N O P Q R S T U V W X Y Z - ,"
fi
fi
fi

for i in $hash_chars; do
newpath="$1/$i"
mkdir $newpath || exit 1
sh $0 $newpath `expr $2 - 1` $3
done

 

3.设置为可执行之后，运行以下命令来创建哈希目录：

#cd /usr/local/server/php/include/php/ext/session/
#./mod_files.sh /tmp/php_sess 2 16


4现在，就开始设置 NFS 共享了。假定有3台主机，ip分别为192.168.0.1(主机名svr1)、192.168.0.2(主机名svr2)、192.168.0.3(主机名svr3)，现在让192.168.0.1来提供NFS共享服务，配置 /etc/exports，加入如下内容：
/tmp/php_sess/ svr*(rw,no_root_squash) #(意思是：允许svr*所以的机器来访问)

 

5.然后重启 nfs 服务，即可对另外两台主机提供NFS共享了。
在 svr2、svr3 上执行以下命令来挂在NFS：
#mkdir /tmp/php_sess
#mount svr1:/tmp/php_sess /tmp/php_sess

 


按上面的配置完成 session NFS 共享，但是问题来了，
我在A服务器上使用PHP脚本如下：
sei.php(文件名)

session_start();
$_SESSION['ID'] ='ABC';
echo $_SESSION['ID'];
?>

然后在B服务下使用PHP脚本如下：
sei.php(文件名)

session_start();
$_SESSION['ID'];
echo $_SESSION['ID'];
?>

测试：A服务能正常显示ABC 但是B服务不能得到A服务访问的session，不显示ABC，显示全是空白。按道理说，按上面session nfs共享配置，我A服务产生了 ABC，我B服务器能自动读取ABC，应该也显示ABC才对啊！！（session NFS共享测试，是不是我PHP脚本有问题？？）
大家帮帮忙。。。

 

 

 

 

 

 

=================================================================
nfs配置+优化+相关基本命令 

NFS配置步骤和优化(转载)
nfs配置                                          
1、NFS包

NFS需要5个RPM，分别是：
setup-*：　　　　共享NFS目录在/etc/exports中定义
initscripts-*：　  包括引导过程中装载网络目录的基本脚本
nfs-utils-*：　　  包括基本的NFS命令与监控程序
portmap-*：　　 支持安全NFS RPC服务的连接
quota-*：　　　　网络上共享的目录配额，包括rpc.rquotad （这个包不是必须的）

2、基本监控程序

要顺利运行NFS，至少需要五个Linux服务，它们各有不同的功能，有的负责装载服务，有的保证远程命令指向正确的位置。这些服务通过/etc/rc.d/init.d目录中的nfs,nfslock和portmap脚本启动。下面简单介绍每个监控程序：

(1) 基本NFS
rpc.nfsd是NFS服务器监控程序，它通过/etc/rc.d/init.d目录中的nfs脚本启动。NFS监控程序还启动rpc.mountd装载监控程序，并导出共享目录。

(2) RPC装载
可以用mount命令连接本地目录或网络目录，但还需要一个装载NFS目录的特殊监控程序rpc.mountd

(3) 端口映射器
portmap监控程序只是定向RPC通信数据流，但它对于NFS服务很重要。如果不运行portmap，则NFS客户机无法找到从NFS服务器共享的目录。

(4) 重新启动与statd
当NFS服务需要中断或者重新启动时，rpc.statd监控程序和rpc.lockd在服务器重新启动之后使客户机恢复NFS连接。

(5) 锁定
通过共享NFS目录打开文件时，锁定可以使用户不能覆盖同一个文件。锁定通过nfslock脚本并使用rpc.lockd监控程序启动运行。

3、配置NFS

共享的NFS目录在/etc/exports中列出，这个文件控制对目录的共享。书写规则是：（每个共享规则一行）

共享目录 主机(参数)

例如：/mnt/cdrom *.abc.com(ro,sync) master.abc.com(rw,sync)

上面的规则代表将/mnt/cdrom目录以只读同步方式共享给*.abc.com域，并且以读写同步方式共享给master.abc.com主机。任何共享目录都要指定sync或async，也就是指定文件写入磁盘之前共享NFS目录是否响应命令。

下面是一些NFS共享的常用参数：
ro：只读访问
rw：读写访问
sync：所有数据在请求时写入共享
async：NFS在写入数据前可以相应请求
secure：NFS通过1024以下的安全TCP/IP端口发送
insecure：NFS通过1024以上的端口发送
wdelay：如果多个用户要写入NFS目录，则归组写入（默认）
no_wdelay：如果多个用户要写入NFS目录，则立即写入，当使用async时，无需此设置。
hide：在NFS共享目录中不共享其子目录
no_hide：共享NFS目录的子目录
subtree_check：如果共享/usr/bin之类的子目录时，强制NFS检查父目录的权限（默认）
no_subtree_check：和上面相对，不检查父目录权限
all_squash：共享文件的UID和GID映射匿名用户anonymous，适合公用目录。
no_all_squash：保留共享文件的UID和GID（默认）
root_squash：root用户的所有请求映射成如anonymous用户一样的权限（默认）
no_root_squash：root用户具有根目录的完全管理访问权限
anonuid=xxx：指定NFS服务器/etc/passwd文件中匿名用户的UID
anongid=xxx：指定NFS服务器/etc/passwd文件中匿名用户的GID

4、启动NFS

# service portmap start  
# service nfs start

或者
#/etc/init.d/nfs start
#/etc/init.d/portmap start
检查NFS的运行级别：
# chkconfig --list portmap
# chkconfig --list nfs

根据需要设置在相应的运行级别自动启动NFS：
# chkconfig --level 235 portmap on
# chkconfig --level 235 nfs on

另外，还需要查看系统的iptables、/etc/hosts.allow、/etc/hosts.deny是否设置了正确的NFS访问规则。

参考：
nfs-howto

nfs优化                                          

1.设置块大小
mount命令的risize和wsize指定了server端和client端的传输的块大小。

mount -t nfs -o rsize=8192,wsizevb=8192,timeo=14,intr client:/partition /partition

如果未指定，系统根据nfs version来设置缺省的risize和wsize大小。大多数情况是4K对于nfs v2，最大是8K，对于v3，通过server端kernel设置risize和wsize的限制

vi /usr/src/linux2.4.22/include/linux/nfsd/const.h
修改常量: NFSSVC_MAXBLKSIZE

所有的2.4的的client都支持最大32K的传输块。系统缺省的块可能会太大或者太小，这主要取决于你的kernel和你的网卡，太大或者太小都有可能导致nfs速度很慢。
具体的可以使用Bonnie，Bonnie++，iozone等benchmark来测试不同risize和wsize下nfs的速度。当然，也可以使用dd来测试。

＃time dd if=/dev/zero of=/testfs/testfile bs=8k count=1024　　测试nfs写
＃time dd if=/testfs/testfile of=/dev/null bs=8k　　　　　　　 测试nfs读

测试时文件的大小至少是系统RAM的两倍，每次测试都使用umount 和mount对/testfs进行挂载，通过比较不同的块大小，得到优化的块大小。


2.网络传输包的大小
网络在包传输过程，对包要进行分组，过大或者过小都不能很好的利用网络的带宽，所以对网络要进行测试和调优。可以使用ping -s 2048 -f hostname进行ping，尝试不同的package size，这样可以看到包的丢失情况。同时，可以使用nfsstat -o net 测试nfs使用udp传输时丢包的多少。因为统计不能清零，所以要先运行此命令记住该值，然后可以再次运行统计。如果，经过上面的统计丢包很多。那么可以看看网络传输包的大小。使用下面的命令：

#tracepath node1/端口号
#ifconfig eth0

比较网卡的mtu和刚刚的pmtu，使用#ifconfig eth0 mtu 16436设置网卡的mtu和测试的一致。 当然如果risize和wsize比mtu的值大，那么的话，server端的包传到client端就要进行重组，这是要消耗client端的cpu资源。此外，包重组可能导致网络的不可信和丢包，任何的丢包都会是的rpc请求重新传输，rpc请求的重传有会导致超时，严重降低nfs的性能。
可以通过查看

/proc/sys/net/ipv4/ipfrag_high_thresh
/proc/sys/net/ipv4/ipfrag_low_thresh

了解系统可以处理的包的数目，如果网络包到达了ipfrag_high_thresh，那么系统就会开始丢包，直到包的数目到达ipfrag_low_thresh。

3.nfs挂载的优化
timeo：　　如果超时，客户端等待的时间，以十分之一秒计算
retrans：　超时尝试的次数。
bg：　　　 后台挂载，很有用
hard：　　 如果server端没有响应，那么客户端一直尝试挂载
wsize：　　写块大小
rsize：　　读块大小
intr：　　 可以中断不成功的挂载
noatime：　不更新文件的inode访问时间，可以提高速度
async：　　异步读写

4.nfsd的个数
缺省的系统在启动时，有8个nfsd进程
#ps -efl|grep nfsd
通过查看/proc/net/rpc/nfsd文件的th行，第一个是nfsd的个数，后十个是线程是用的时间数，第二个到第四个值如果很大，那么就需要增加nfsd的个数。
具体如下：

#vi /etc/init.d/nfs

找到RPCNFSDCOUNT,修改该值，一般和client端数目一致。

#service nfs restart
#mount -a

5.nfsd的队列长度
对于8个nfsd进程，系统的nfsd队列长度是64k大小，如果是多于8个，就要相应的增加相应的队列大小，具体的在

/proc/sys/net/core/rwmem_default
/proc/sys/net/core/wwmem_default
/proc/sys/net/core/rmmem_max
/proc/sys/net/core/wmmem_max

队列的长度最好是每一个nfsd有8k的大小。这样，server端就可以对client的请求作排队处理。如果要永久更改此值

#vi /etc/sysctl.conf
net.core.rmmem_default=数目
net.core.wmmem_default=数目
net.core.rmmem_max=数目
net.core.wmmem_max=数目
#service nfs restart


++
查看被导出资源
showmount -e nfsserver_name(or nfsserver IP address)
重新加载配置：
exportfs -rv
停止现在发布的目录
exportfs -a

 

 

===============================================================================
Centos64bit_5.3 默认值：
[root@qy init.d]# cat /proc/sys/net/core/rmem_default
126976         124K
[root@qy init.d]# cat /proc/sys/net/core/rmem_max
131071         127.xxxK
